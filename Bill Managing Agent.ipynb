{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOFKepj_l1Ub",
        "outputId": "bf4d7145-35f3-4996-dd2b-6cf06360abff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.1.1-2.1build1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 30 not upgraded.\n",
            "Requirement already satisfied: pyautogen in /usr/local/lib/python3.11/dist-packages (0.8.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\n",
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.11/dist-packages (0.3.13)\n",
            "Requirement already satisfied: anyio<5.0.0,>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from pyautogen) (4.9.0)\n",
            "Requirement already satisfied: asyncer==0.0.8 in /usr/local/lib/python3.11/dist-packages (from pyautogen) (0.0.8)\n",
            "Requirement already satisfied: diskcache in /usr/local/lib/python3.11/dist-packages (from pyautogen) (5.6.3)\n",
            "Requirement already satisfied: docker in /usr/local/lib/python3.11/dist-packages (from pyautogen) (7.1.0)\n",
            "Requirement already satisfied: httpx<1,>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from pyautogen) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from pyautogen) (24.2)\n",
            "Requirement already satisfied: pydantic<3,>=2.6.1 in /usr/local/lib/python3.11/dist-packages (from pyautogen) (2.11.2)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (from pyautogen) (1.1.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from pyautogen) (3.0.1)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from pyautogen) (0.9.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0.0,>=3.0.0->pyautogen) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0.0,>=3.0.0->pyautogen) (1.3.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0.0,>=3.0.0->pyautogen) (4.13.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.28.1->pyautogen) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.28.1->pyautogen) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.28.1->pyautogen) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6.1->pyautogen) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6.1->pyautogen) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6.1->pyautogen) (0.4.0)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from docker->pyautogen) (2.32.3)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from docker->pyautogen) (2.3.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->pyautogen) (2024.11.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->docker->pyautogen) (3.4.1)\n",
            "User_Proxy (to chat_manager):\n",
            "\n",
            "Please process these bill images: ['/content/bill.jpg']\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Next speaker: Bill_Processor\n",
            "\n",
            "Bill_Processor (to chat_manager):\n",
            "\n",
            "Sure, to process the bill images, we will use the `process_bill_images` function. However, as an AI model, I don't have the ability to execute code. Here's how you can do it:\n",
            "\n",
            "```python\n",
            "# Assuming you have a function defined as process_bill_images\n",
            "processed_bills = process_bill_images(['/content/bill.jpg'])\n",
            "```\n",
            "\n",
            "This function will process the image at the path '/content/bill.jpg' using OCR and LLM extraction. Please make sure that the function `process_bill_images` is properly defined and the path to the image is correct.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Next speaker: User_Proxy\n",
            "\n",
            "User_Proxy (to chat_manager):\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Next speaker: User_Proxy\n",
            "\n",
            "User_Proxy (to chat_manager):\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Next speaker: User_Proxy\n",
            "\n",
            "User_Proxy (to chat_manager):\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Next speaker: User_Proxy\n",
            "\n",
            "User_Proxy (to chat_manager):\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            ">>>>>>>> TERMINATING RUN (ddf8f31d-18c6-4718-8f0f-d4b1dad74506): Maximum rounds (6) reached\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "ChatResult(chat_id=None, chat_history=[{'content': \"Please process these bill images: ['/content/bill.jpg']\", 'role': 'assistant', 'name': 'User_Proxy'}, {'content': \"Sure, to process the bill images, we will use the `process_bill_images` function. However, as an AI model, I don't have the ability to execute code. Here's how you can do it:\\n\\n```python\\n# Assuming you have a function defined as process_bill_images\\nprocessed_bills = process_bill_images(['/content/bill.jpg'])\\n```\\n\\nThis function will process the image at the path '/content/bill.jpg' using OCR and LLM extraction. Please make sure that the function `process_bill_images` is properly defined and the path to the image is correct.\", 'name': 'Bill_Processor', 'role': 'user'}, {'content': '', 'role': 'assistant', 'name': 'User_Proxy'}, {'content': '', 'role': 'assistant', 'name': 'User_Proxy'}, {'content': '', 'role': 'assistant', 'name': 'User_Proxy'}, {'content': '', 'role': 'assistant', 'name': 'User_Proxy'}], summary='', cost={'usage_including_cached_inference': {'total_cost': 0}, 'usage_excluding_cached_inference': {'total_cost': 0}}, human_input=[])"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "!sudo apt install tesseract-ocr\n",
        "!pip install pyautogen pillow pytesseract\n",
        "\n",
        "import os\n",
        "import json\n",
        "from PIL import Image\n",
        "import pytesseract\n",
        "import autogen\n",
        "from autogen import GroupChat, GroupChatManager, UserProxyAgent, AssistantAgent\n",
        "\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = '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'\n",
        "\n",
        "config_list = [\n",
        "    {\n",
        "        'model': 'gpt-4',\n",
        "        'api_key': os.environ['OPENAI_API_KEY']\n",
        "    }\n",
        "]\n",
        "\n",
        "llm_config = {\n",
        "    \"config_list\": config_list,\n",
        "    \"temperature\": 0\n",
        "}\n",
        "\n",
        "def process_bill_images(image_paths):\n",
        "    expenses = []\n",
        "    for path in image_paths:\n",
        "        try:\n",
        "            img = Image.open(path)\n",
        "            text = pytesseract.image_to_string(img)\n",
        "\n",
        "\n",
        "            prompt = f\"\"\"Analyze this bill text and extract expenses:\n",
        "            {text}\n",
        "\n",
        "            Return JSON format with:\n",
        "            - description (item/service name)\n",
        "            - amount (numeric value)\n",
        "            - category (groceries/dining/utilities/shopping/entertainment/other)\"\"\"\n",
        "\n",
        "\n",
        "            from openai import OpenAI\n",
        "            client = OpenAI()\n",
        "            response = client.chat.completions.create(\n",
        "                model=\"gpt-4\",\n",
        "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "                temperature=0\n",
        "            )\n",
        "\n",
        "            items = json.loads(response.choices[0].message.content)\n",
        "            expenses.extend(items)\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {path}: {str(e)}\")\n",
        "\n",
        "    # Categorize expenses\n",
        "    categories = {\n",
        "        'groceries': 0.0,\n",
        "        'dining': 0.0,\n",
        "        'utilities': 0.0,\n",
        "        'shopping': 0.0,\n",
        "        'entertainment': 0.0,\n",
        "        'other': 0.0\n",
        "    }\n",
        "\n",
        "    for item in expenses:\n",
        "        cat = item['category'].lower()\n",
        "        categories[cat] += float(item['amount']) if cat in categories else categories['other']\n",
        "\n",
        "    return {\n",
        "        'raw_expenses': expenses,\n",
        "        'category_totals': categories\n",
        "    }\n",
        "\n",
        "def summarize_expenses(categorized_data):\n",
        "    totals = categorized_data['category_totals']\n",
        "    summary = \"📊 Spending Summary:\\n\\n\"\n",
        "\n",
        "    # Total spending\n",
        "    total = sum(totals.values())\n",
        "    summary += f\"💵 Total Expenditure: ${total:.2f}\\n\\n\"\n",
        "\n",
        "    # Breakdown by category\n",
        "    summary += \"📈 Category Breakdown:\\n\"\n",
        "    for cat, amount in totals.items():\n",
        "        if amount > 0:\n",
        "            summary += f\"- {cat.capitalize()}: ${amount:.2f}\\n\"\n",
        "\n",
        "    # Highlight highest category\n",
        "    max_cat = max(totals, key=totals.get)\n",
        "    summary += f\"\\n🔥 Highest Spending: {max_cat.capitalize()} (${totals[max_cat]:.2f})\\n\"\n",
        "\n",
        "    # Alert for unusual spending\n",
        "    avg = total / len([v for v in totals.values() if v > 0])\n",
        "    alerts = [cat for cat, amt in totals.items() if amt > 3 * avg]\n",
        "    if alerts:\n",
        "        summary += \"\\n🚨 Unusual Spending Alert:\\n\"\n",
        "        summary += \"\\n\".join(f\"- {cat.capitalize()}\" for cat in alerts)\n",
        "\n",
        "    return summary\n",
        "\n",
        "# Create Agents\n",
        "user_proxy = UserProxyAgent(\n",
        "    name=\"User_Proxy\",\n",
        "    human_input_mode=\"NEVER\",\n",
        "    system_message=\"A user proxy that initiates bill processing by providing image paths.\",\n",
        "    code_execution_config=False\n",
        ")\n",
        "\n",
        "bill_processor = AssistantAgent(\n",
        "    name=\"Bill_Processor\",\n",
        "    system_message=\"You process bill images using OCR and LLM extraction. Use process_bill_images function for all image processing tasks.\",\n",
        "    llm_config=llm_config,\n",
        "    function_map={\"process_bill_images\": process_bill_images}\n",
        ")\n",
        "\n",
        "expense_analyst = AssistantAgent(\n",
        "    name=\"Expense_Analyst\",\n",
        "    system_message=\"You analyze categorized expenses and generate summaries. Use summarize_expenses function for all analysis tasks.\",\n",
        "    llm_config=llm_config,\n",
        "    function_map={\"summarize_expenses\": summarize_expenses}\n",
        ")\n",
        "\n",
        "# Configure Group Chat\n",
        "group_chat = GroupChat(\n",
        "    agents=[user_proxy, bill_processor, expense_analyst],\n",
        "    messages=[],\n",
        "    max_round=6\n",
        ")\n",
        "\n",
        "manager = GroupChatManager(\n",
        "    groupchat=group_chat,\n",
        "    llm_config=llm_config\n",
        ")\n",
        "\n",
        "# Initiate chat with example image (upload your bills in Colab first)\n",
        "user_proxy.initiate_chat(\n",
        "    manager,\n",
        "    message=\"Please process these bill images: ['/content/bill.jpg']\"\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
